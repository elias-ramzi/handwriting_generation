{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elias/work/descript-research-test\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import DataSynthesis\n",
    "from utils import plot_stroke\n",
    "from models.handwriting_synthesis import HandWritingSynthesis\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'models/trained/test/model_synthesis_overfit.h5'\n",
    "EPOCH_MODEL_PATH = 'models/trained/test/model_synthesis_overfit_{}.h5'\n",
    "LOAD_PREVIOUS = None\n",
    "DATA_PATH = 'data/strokes-py3.npy'\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "model_kwargs = {\n",
    "    'regularizer_type': 'l2',\n",
    "    'reg_mean': 0.,\n",
    "    'reg_std': 0.,\n",
    "    'reg_l2': 0.,\n",
    "    'lr': .0001,\n",
    "    'rho': .95,\n",
    "    'momentum': .9,\n",
    "    'epsilon': .0001,\n",
    "    'centered': True,\n",
    "    'inf_type': 'max',\n",
    "}\n",
    "\n",
    "HIDDEN_DIM = 400\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "data_kwargs = {\n",
    "    'path_to_data': DATA_PATH,\n",
    "}\n",
    "\n",
    "train_generator_kwargs = {\n",
    "    'batch_size': 1,\n",
    "    'shuffle': False,\n",
    "}\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH = 100\n",
    "MODEL_CHECKPOINT = 5\n",
    "\n",
    "# bias for writing ~~style~~\n",
    "BIAS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DataSynthesis(**data_kwargs)\n",
    "WINDOW_SIZE = len(D.sentences[0][0])\n",
    "\n",
    "model_kwargs['vocab_size'] = WINDOW_SIZE\n",
    "hws = HandWritingSynthesis(**model_kwargs)\n",
    "\n",
    "nan = False\n",
    "generator = D.batch_generator(\n",
    "    **train_generator_kwargs,\n",
    ")\n",
    "\n",
    "input_states = [\n",
    "    # stateh1, statec1\n",
    "    tf.zeros((1, HIDDEN_DIM), dtype=float), tf.zeros((1, HIDDEN_DIM), dtype=float),\n",
    "    # stateh2, statec2\n",
    "    tf.zeros((1, HIDDEN_DIM), dtype=float), tf.zeros((1, HIDDEN_DIM), dtype=float),\n",
    "    # stateh3, statec3\n",
    "    tf.zeros((1, HIDDEN_DIM), dtype=float), tf.zeros((1, HIDDEN_DIM), dtype=float),\n",
    "    # window kappa\n",
    "    tf.zeros((1, WINDOW_SIZE), dtype=float), tf.zeros((1, 10), dtype=float),\n",
    "    # phi, alpha, beta\n",
    "    tf.zeros((1, 1), dtype=float), tf.zeros((1, 10), dtype=float), tf.zeros((1, 10), dtype=float),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for overfitting\n",
    "strokes, sentence, targets = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, EPOCHS + 1):\n",
    "    train_loss = []\n",
    "    for s in tqdm(range(1, STEPS_PER_EPOCH+1), desc=\"Epoch {}/{}\".format(e, EPOCHS)):\n",
    "        # strokes, sentence, targets = next(generator)\n",
    "        loss = hws.train(strokes, sentence, input_states, targets)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        if loss is np.nan:\n",
    "            nan = True\n",
    "            print('exiting train @epoch : {}'.format(e))\n",
    "            break\n",
    "\n",
    "    mean_loss = np.mean(train_loss)\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}\".format(e, mean_loss))\n",
    "\n",
    "    if e % MODEL_CHECKPOINT == 0:\n",
    "        hws.save_weights(EPOCH_MODEL_PATH.format(e))\n",
    "\n",
    "    if nan:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not nan:\n",
    "    hws.save_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose_sentence = \"\".join(D.encoder.inverse_transform(sentence)[0])\n",
    "strokes1, windows, phis, kappas, alphas, betas = hws.infer(sentence, inf_type='max', verbose=verbose_sentence)\n",
    "plot_stroke(strokes1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
